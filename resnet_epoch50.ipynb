{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(planes)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride !=1 or in_planes != planes * self.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * self.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(identity)\n",
    "        out = self.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=100):  # 设置为100类\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1  = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1    = nn.BatchNorm2d(64)\n",
    "        self.relu   = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, 64,  num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.avgpool= nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc     = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks - 1)\n",
    "        layers  = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out  # 返回最终输出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_label_names = [\n",
    "    'aquatic mammals', 'fish', 'flowers', 'food containers', 'fruit and vegetables',\n",
    "    'household electrical devices', 'household furniture', 'insects', 'large carnivores',\n",
    "    'largxe man-made outdoor things', 'large natural outdoor scenes', 'large omnivores and herbivores',\n",
    "    'medium-sized mammals', 'non-insect invertebrates', 'people', 'reptiles', 'small mammals',\n",
    "    'trees', 'vehicles 1', 'vehicles 2'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_label_names = [\n",
    "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver',\n",
    "    'bed', 'bee', 'beetle', 'bicycle', 'bottle',\n",
    "    'bowl', 'boy', 'bridge', 'bus', 'butterfly',\n",
    "    'camel', 'can', 'castle', 'caterpillar', 'cattle',\n",
    "    'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach',\n",
    "    'couch', 'crab', 'crocodile', 'cup', 'dinosaur',\n",
    "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox',\n",
    "    'girl', 'hamster', 'house', 'kangaroo', 'keyboard',\n",
    "    'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard',\n",
    "    'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain',\n",
    "    'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid',\n",
    "    'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree',\n",
    "    'plain', 'plate', 'poppy', 'porcupine', 'possum',\n",
    "    'rabbit', 'raccoon', 'ray', 'road', 'rocket',\n",
    "    'rose', 'sea', 'seal', 'shark', 'shrew',\n",
    "    'skunk', 'skyscraper', 'snail', 'snake', 'spider',\n",
    "    'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
    "    'tank', 'telephone', 'television', 'tiger', 'tractor',\n",
    "    'train', 'trout', 'tulip', 'turtle', 'wardrobe',\n",
    "    'whale', 'willow_tree', 'wolf', 'woman', 'worm'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建细粒度标签到粗粒度标签的映射\n",
    "# CIFAR-100数据集的每个超级类别包含5个细粒度类别，按顺序排列\n",
    "fine_to_coarse = {}\n",
    "for coarse_label in range(20):\n",
    "    for i in range(5):\n",
    "        fine_label = coarse_label * 5 + i\n",
    "        fine_to_coarse[fine_label] = coarse_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印超级类别1和5的信息\n",
    "print(\"Superclass 1:\", coarse_label_names[1])\n",
    "print(\"Superclass 5:\", coarse_label_names[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408),\n",
    "                         (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408),\n",
    "                         (0.2675, 0.2565, 0.2761)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载完整的训练数据集\n",
    "full_trainset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练集和验证集的大小\n",
    "train_size = int(0.9 * len(full_trainset))\n",
    "val_size = len(full_trainset) - train_size\n",
    "\n",
    "# 设置随机种子以确保可重复性\n",
    "torch.manual_seed(42)\n",
    "trainset, valset = random_split(full_trainset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据加载器\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "    valset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# 加载测试数据集\n",
    "testset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=64, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学习率调度器\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型并记录准确率\n",
    "num_epochs = 50\n",
    "\n",
    "train_acc_list = []\n",
    "val_acc_list = []\n",
    "\n",
    "best_val_acc = 0  # 用于保存最佳模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # 训练阶段\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = outputs.topk(5, 1, True, True)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted[:, 0] == labels).sum().item()\n",
    "\n",
    "    train_acc = 100. * correct / total\n",
    "    train_acc_list.append(train_acc)\n",
    "    print(\n",
    "        f'Epoch [{epoch+1}/{num_epochs}] completed. Training Loss: {running_loss/len(trainloader):.4f}, Training Top-1 Acc: {train_acc:.2f}%')\n",
    "\n",
    "    # 验证阶段\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "\n",
    "    # 用于计算超级类别的准确率\n",
    "    correct_superclass = 0\n",
    "    total_superclass = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.topk(5, 1, True, True)\n",
    "            total += labels.size(0)\n",
    "            correct_top1 += (predicted[:, 0] == labels).sum().item()\n",
    "            correct_top5 += sum([labels[i].item() in predicted[i].cpu().numpy()\n",
    "                                 for i in range(labels.size(0))])\n",
    "\n",
    "            # 超级类别准确率计算\n",
    "            labels_coarse = torch.tensor(\n",
    "                [fine_to_coarse[label.item()] for label in labels], device=device)\n",
    "            predicted_coarse = torch.tensor(\n",
    "                [fine_to_coarse[pred.item()] for pred in predicted[:, 0]], device=device)\n",
    "            correct_superclass += (\n",
    "                predicted_coarse == labels_coarse).sum().item()\n",
    "            total_superclass += labels.size(0)\n",
    "\n",
    "    val_acc_top1 = 100. * correct_top1 / total\n",
    "    val_acc_top5 = 100. * correct_top5 / total\n",
    "    val_acc_superclass = 100. * correct_superclass / total_superclass\n",
    "    val_acc_list.append(val_acc_top1)\n",
    "\n",
    "    print(f'Validation Loss: {val_loss/len(valloader):.4f}')\n",
    "    print(f'Top-1 Validation Accuracy: {val_acc_top1:.2f}%')\n",
    "    print(f'Top-5 Validation Accuracy: {val_acc_top5:.2f}%')\n",
    "    print(f'Top-1 Superclass Validation Accuracy: {val_acc_superclass:.2f}%')\n",
    "\n",
    "    # 保存最佳模型\n",
    "    if val_acc_top1 > best_val_acc:\n",
    "        best_val_acc = val_acc_top1\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "    # 更新学习率\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制训练和验证准确率曲线\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs+1), train_acc_list,\n",
    "         label='Train Top-1 Accuracy')\n",
    "plt.plot(range(1, num_epochs+1), val_acc_list,\n",
    "         label='Validation Top-1 Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training and Validation Top-1 Accuracy over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在测试集上进行最终评估\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "correct_top1 = 0\n",
    "correct_top5 = 0\n",
    "total = 0\n",
    "\n",
    "# 用于计算超级类别的准确率\n",
    "correct_superclass = 0\n",
    "total_superclass = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.topk(5, 1, True, True)\n",
    "        total += labels.size(0)\n",
    "        correct_top1 += (predicted[:, 0] == labels).sum().item()\n",
    "        correct_top5 += sum([labels[i].item() in predicted[i].cpu().numpy()\n",
    "                             for i in range(labels.size(0))])\n",
    "\n",
    "        # 超级类别准确率计算\n",
    "        labels_coarse = torch.tensor(\n",
    "            [fine_to_coarse[label.item()] for label in labels], device=device)\n",
    "        predicted_coarse = torch.tensor(\n",
    "            [fine_to_coarse[pred.item()] for pred in predicted[:, 0]], device=device)\n",
    "        correct_superclass += (\n",
    "            predicted_coarse == labels_coarse).sum().item()\n",
    "        total_superclass += labels.size(0)\n",
    "\n",
    "test_acc_top1 = 100. * correct_top1 / total\n",
    "test_acc_top5 = 100. * correct_top5 / total\n",
    "test_acc_superclass = 100. * correct_superclass / total_superclass\n",
    "\n",
    "print('Final Test Results:')\n",
    "print(f'Test Loss: {test_loss/len(testloader):.4f}')\n",
    "print(f'Top-1 Test Accuracy: {test_acc_top1:.2f}%')\n",
    "print(f'Top-5 Test Accuracy: {test_acc_top5:.2f}%')\n",
    "print(f'Top-1 Superclass Test Accuracy: {test_acc_superclass:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
